{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0UWva5CanUl",
        "outputId": "1476d459-4d52-4950-f5e4-70c3bba9d230"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHyx7jyQ6i2y"
      },
      "outputs": [],
      "source": [
        "hr_knowledge = [\n",
        "\n",
        "\"Human Resources professionals are responsible for recruitment, onboarding, and employee relations.\",\n",
        "\"HR departments manage payroll, benefits administration, and compliance with labor laws.\",\n",
        "\"Human Resources teams support performance evaluation and workforce planning.\",\n",
        "\"HR professionals handle conflict resolution and employee engagement initiatives.\",\n",
        "\"Talent acquisition is a core function of Human Resources.\",\n",
        "\"HR specialists often coordinate training and professional development programs.\",\n",
        "\"Human Resources supports organizational culture and diversity initiatives.\",\n",
        "\"HR roles involve maintaining employee records and ensuring policy compliance.\",\n",
        "\"Recruitment and hiring are central responsibilities in HR positions.\",\n",
        "\"HR professionals work closely with management to support strategic staffing decisions.\",\n",
        "\"Key skills for HR professionals include communication, interpersonal skills, and organizational ability.\",\n",
        "\n",
        "\"HR roles require knowledge of employment law and workplace regulations.\",\n",
        "\"Strong problem-solving and conflict management skills are important in HR.\",\n",
        "\"Human Resources professionals need attention to detail and confidentiality.\",\n",
        "\"HR positions require administrative and coordination skills.\",\n",
        "\"People management and employee support skills are essential in HR careers.\",\n",
        "\n",
        "\"Entry-level HR roles include HR Assistant, HR Coordinator, and Recruiting Intern.\",\n",
        "\"Aspiring HR professionals often start in talent acquisition or people operations roles.\",\n",
        "\"Internships in recruitment or employee engagement are common entry paths into HR.\",\n",
        "\"HR assistants support senior HR managers with administrative tasks.\",\n",
        "\"People Operations roles are closely related to Human Resources functions.\",\n",
        "\n",
        "\"Job titles such as HR Generalist, HR Assistant, and Recruiter are directly related to Human Resources.\",\n",
        "\"People Operations Specialist roles are often equivalent to HR positions.\",\n",
        "\"Talent Acquisition Specialist is a common HR-related title.\",\n",
        "\"Employee Relations Coordinator works within the HR function.\",\n",
        "\"Compensation and Benefits Analyst is part of Human Resources.\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers faiss-cpu\n",
        "!pip install -q \\\n",
        "    transformers>=4.38.0 \\\n",
        "    sentence-transformers \\\n",
        "    faiss-cpu \\\n",
        "    accelerate \\\n",
        "    bitsandbytes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7xFCn418SmZ",
        "outputId": "1b4aec58-e73d-4788-e82e-31a08bc35a65",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (5.0.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (26.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (8.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "print(\"Generator model loaded.\")\n"
      ],
      "metadata": {
        "id": "qPNzvGhb86XI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "collapsed": true,
        "outputId": "7868f92d-ae1a-43da-dada-12564ca69ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: False\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2898181889.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA available:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Device:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Qwen/Qwen2.5-7B-Instruct\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \"\"\"\n\u001b[0;32m--> 582\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0m_CudaDeviceProperties\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproperties\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \"\"\"\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    401\u001b[0m             )\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cuda_getDeviceCount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             raise AssertionError(\n",
            "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Apziva/ProjectC.csv\")\n",
        "df = df.drop_duplicates(subset=['job_title'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "L2BGf7bj-vg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "doc_embeddings = embed_model.encode(hr_knowledge)\n",
        "doc_embeddings = np.array(doc_embeddings).astype(\"float32\")\n",
        "\n",
        "index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n",
        "index.add(doc_embeddings)\n",
        "\n",
        "print(\"Vector index built.\")\n",
        "print(\"Total documents indexed:\", len(hr_knowledge))\n"
      ],
      "metadata": {
        "id": "aQMeNIKN8Zug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context(query, k=3):\n",
        "    query_embedding = embed_model.encode([query]).astype(\"float32\")\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    return [hr_knowledge[i] for i in indices[0]]\n",
        "\n",
        "def build_equivalence_prompt(title_a, title_b):\n",
        "    prompt = f\"\"\"\n",
        "You are an expert HR recruiter.\n",
        "\n",
        "Determine whether the following two job titles refer to the same or nearly the same role.\n",
        "\n",
        "Consider:\n",
        "- Abbreviations (e.g., HR = Human Resources)\n",
        "- Synonyms\n",
        "- Minor wording differences\n",
        "- Singular/plural differences\n",
        "\n",
        "If they describe essentially the same job function in practice, answer Yes.\n",
        "Otherwise answer No.\n",
        "\n",
        "IMPORTANT:\n",
        "- Output ONLY one word: Yes or No.\n",
        "- Do not explain.\n",
        "\n",
        "A: {title_a}\n",
        "B: {title_b}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "def build_rag_pair_prompt(title_a, title_b, target_role):\n",
        "\n",
        "    context_docs = retrieve_context(target_role, k=10)\n",
        "    context = \"\\n\".join(context_docs)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an expert HR recruiter.\n",
        "\n",
        "Target Role:\n",
        "{target_role}\n",
        "\n",
        "Relevant Background Information:\n",
        "{context}\n",
        "\n",
        "Compare the following job titles:\n",
        "\n",
        "A: {title_a}\n",
        "B: {title_b}\n",
        "\n",
        "Which title is more suitable?\n",
        "Answer guidance:\n",
        "- The first line must be one of: A or B\n",
        "- Choose A if it is more relevant to the target role.\n",
        "- Choose B if it is more relevant to the target role.\n",
        "- Even if both are weakly relevant, choose the more suitable one.\n",
        "- Output ONLY one character: A or B.\n",
        "- Do not default to A; follow the suitability logic strictly.\n",
        "Answer:\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "def generate_answer(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=3,\n",
        "        do_sample=False,\n",
        "        temperature=0.0\n",
        "    )\n",
        "\n",
        "    generated_tokens = outputs[0][inputs[\"input_ids\"].shape[-1]:]\n",
        "    result = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
        "    return result\n",
        "\n",
        "def rag_pairwise_winner(title_a, title_b):\n",
        "    target_role = \"Aspiring Human Resources\"\n",
        "    eq_prompt = build_equivalence_prompt(title_a, title_b)\n",
        "    eq_result = generate_answer(eq_prompt)\n",
        "\n",
        "    if eq_result.startswith(\"Yes\"):\n",
        "        return \"Tie\"\n",
        "\n",
        "    comp_prompt = build_rag_pair_prompt(title_a, title_b, target_role)\n",
        "    comp_result = generate_answer(comp_prompt)\n",
        "\n",
        "    if comp_result.startswith(\"A\"):\n",
        "        return \"A：\" + title_a\n",
        "    elif comp_result.startswith(\"B\"):\n",
        "        return \"B：\" + title_b\n",
        "    else:\n",
        "        # fallback 安全机制\n",
        "        return \"Error\""
      ],
      "metadata": {
        "id": "2q3kziMj8hTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_a = \"HR Assistant\"\n",
        "title_b = \"Human Resource Assistant\"\n",
        "\n",
        "winner = rag_pairwise_winner(title_a, title_b)\n",
        "print(\"Winner:\", winner)\n",
        "\n",
        "title_a = \"English Teacher\"\n",
        "title_b = \"Marketing Data Analyst\"\n",
        "\n",
        "winner = rag_pairwise_winner(title_a, title_b)\n",
        "print(\"Winner:\", winner)\n",
        "\n",
        "title_a = \"People Operations Intern\"\n",
        "title_b = \"Marketing Data Analyst\"\n",
        "\n",
        "winner = rag_pairwise_winner(title_a, title_b)\n",
        "print(\"Winner:\", winner)"
      ],
      "metadata": {
        "id": "9wMWIZIX-G9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "\n",
        "def rag_pairwise_sort(df, title_col=\"job_title\"):\n",
        "\n",
        "    titles = df[title_col].tolist()\n",
        "    n = len(titles)\n",
        "    scores = [0] * n\n",
        "    pairwise_results = []\n",
        "\n",
        "    for i in range(n):\n",
        "        print(f\"Processing {i+1}/{n} titles...\")\n",
        "        for j in range(i+1, n):\n",
        "\n",
        "            winner = rag_pairwise_winner(titles[i], titles[j])\n",
        "\n",
        "            pairwise_results.append({\n",
        "                \"A\": titles[i],\n",
        "                \"B\": titles[j],\n",
        "                \"winner\": winner\n",
        "            })\n",
        "\n",
        "            if winner == titles[i]:\n",
        "                scores[i] += 1\n",
        "            elif winner == titles[j]:\n",
        "                scores[j] += 1\n",
        "            else:\n",
        "                scores[i] += 0.5\n",
        "                scores[j] += 0.5\n",
        "\n",
        "    sorted_df = pd.DataFrame({\n",
        "        \"job_title\": titles,\n",
        "        \"score\": scores\n",
        "    }).sort_values(by=\"score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    pairwise_df = pd.DataFrame(pairwise_results)\n",
        "\n",
        "    return sorted_df, pairwise_df\n",
        "\n",
        "sorted_df, pairwise_df = rag_pairwise_sort(df, title_col=\"job_title\")\n",
        "print(sorted_df)\n"
      ],
      "metadata": {
        "id": "zKcKqz1Y8imQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d042c4fd-f538-4430-d932-4e1cae753bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1/52 titles...\n",
            "Processing 2/52 titles...\n",
            "Processing 3/52 titles...\n",
            "Processing 4/52 titles...\n",
            "Processing 5/52 titles...\n",
            "Processing 6/52 titles...\n",
            "Processing 7/52 titles...\n",
            "Processing 8/52 titles...\n",
            "Processing 9/52 titles...\n",
            "Processing 10/52 titles...\n",
            "Processing 11/52 titles...\n",
            "Processing 12/52 titles...\n",
            "Processing 13/52 titles...\n",
            "Processing 14/52 titles...\n",
            "Processing 15/52 titles...\n",
            "Processing 16/52 titles...\n",
            "Processing 17/52 titles...\n",
            "Processing 18/52 titles...\n",
            "Processing 19/52 titles...\n",
            "Processing 20/52 titles...\n",
            "Processing 21/52 titles...\n",
            "Processing 22/52 titles...\n",
            "Processing 23/52 titles...\n",
            "Processing 24/52 titles...\n",
            "Processing 25/52 titles...\n",
            "Processing 26/52 titles...\n",
            "Processing 27/52 titles...\n",
            "Processing 28/52 titles...\n",
            "Processing 29/52 titles...\n",
            "Processing 30/52 titles...\n",
            "Processing 31/52 titles...\n",
            "Processing 32/52 titles...\n",
            "Processing 33/52 titles...\n",
            "Processing 34/52 titles...\n",
            "Processing 35/52 titles...\n",
            "Processing 36/52 titles...\n",
            "Processing 37/52 titles...\n",
            "Processing 38/52 titles...\n",
            "Processing 39/52 titles...\n",
            "Processing 40/52 titles...\n",
            "Processing 41/52 titles...\n",
            "Processing 42/52 titles...\n",
            "Processing 43/52 titles...\n",
            "Processing 44/52 titles...\n",
            "Processing 45/52 titles...\n",
            "Processing 46/52 titles...\n",
            "Processing 47/52 titles...\n",
            "Processing 48/52 titles...\n",
            "Processing 49/52 titles...\n",
            "Processing 50/52 titles...\n",
            "Processing 51/52 titles...\n",
            "Processing 52/52 titles...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "YxGG8nGsCEnJ",
        "outputId": "2a4dc745-9e84-48d0-896d-7b41a48631fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sorted_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3903207919.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sorted_df' is not defined"
          ]
        }
      ]
    }
  ]
}